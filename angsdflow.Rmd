---
title: "Estimating the Site Frequency Spectrum, Thetas and Tajima's D using ANGSD"
output: html_document
---
<br>
<br>


This is a document detailing how to process mapped NGS reads (sorted and indexed .bam files), and derive the SFS, site-wise estimates of Theta and Tajima's D using [ANGSD](http://popgen.dk/wiki/index.php/ANGSD). This is based on the wiki entry [here](http://popgen.dk/angsd/index.php/Tajima). At the moment this is estiamted based on several teosinte samples from the HapMap2 project. These are stored on Farm in 

* /group/jrigrp3/bottleneckProject/mergedBams

The examples TIL\*.bam are all teosinte, but TIL8 and TIL25 are *Z. mays mexicana* and will be removed from future analysis. The remiaing TIL\*.bam accessions are all *Zea mays parviglumis* and can be analysed together. 

In order to process the data the order of opporations should be roughly:

1.  Estiamte the SFS.
2.  Estimate Thetas
3.  Measure Statistics of deviation from neutrality.

Below is an example of work flow given in the [wiki](http://popgen.dk/angsd/index.php/Tajima), enabling the eventual estimation of Tajima's D.<br>

<br>

```{r,wrapper=TRUE, eval=FALSE}
    ./angsd -bam bam.filelist -doSaf 1 -anc chimpHg19.fa -GL 2 -P 24 -out out 
    ./misc/realSFS out.saf 20 -P 24 > out.sfs
    ./angsd -bam bam.filelist -out out -doThetas 1 -doSaf 1 -pest out.sfs -anc chimpHg19.fa -GL 2
    ./misc/thetaStat make_bed out.thetas.gz
    #Estimate for every Chromosome/scaffold
    ./misc/thetaStat do_stat out.thetas.gz -nChr 20
    #Do a sliding window analysis based on the output from the make_bed command.
    ./misc/thetaStat do_stat out.thetas.gz -nChr 20 -win 50000 -step 10000  -outnames theta.thetasWindow.gz
```

<br>

###Step1: Estimating the SFS in Teosinte (*Zea mays ssp. parviglumis*)

First estimate the site allele frequency likelihood. This requires several things listed below:

**1**.  A file with listed, one per line, all the .bam files you want to analyse. You can grab the files you need by cd'ing to the dir they are in and executing this code on the command line. 
<br>

```{r,wrapper=TRUE, eval=FALSE}
ls $PWD/*.bam > bam.list
```
<br>

**2**.  Choose which method you want to use with: 

```{r,wrapper=TRUE, eval=FALSE}
-doSaf [int 1-4]
```

There are four options listed in detail [here](http://popgen.dk/angsd/index.php/SFS_Estimation).

<br>

**3**. Define your ancestral allele using the flag:
```{r,wrapper=TRUE, eval=FALSE}
-anc <path/to/referencegenome>
```

In my case we do not know the ancestral allele state, which means instead of derived allele SFS we need a minor allele SFS (a folded SFS). We can still provide an ancestral estimate using the reference genome (B73), but once folding is complete in becomes a minor allele SFS. We need to specify that we want a folded SFS wiht:
```{r,wrapper=TRUE, eval=FALSE}
-fold 1
```
<br>

**4**.  Define the method for estimating Genotype Likelihoods:
```{r,wrapper=TRUE, eval=FALSE}
-GL [int 1-4]
```

details of the different methods are provided [here](http://popgen.dk/angsd/index.php/Genotype_likelihoods).

<br>


**5**. Define the number of processors to use with:
```{r,wrapper=TRUE, eval=FALSE}
-P [int]
```
 
 <br>
 
**6**. Define the outfile name using:
```{r,wrapper=TRUE, eval=FALSE}
-out <path/to/outfile>
```
there are several output files and a suffix will be added to each file.

<br>

You can also define the region of the genome you would like to analyse. On the first pass we will limit our analysis of the genome to the first 500,000 bp of chromosome 10 using:


```{r,wrapper=TRUE, eval=FALSE}
-r 10:1-100000
```

I have a bam.list file that has the following accessions listed:

```{r,wrapper=TRUE, eval=FALSE}
/home/sbyfield/HapMap2Teo/TIL01_merged.bam
/home/sbyfield/HapMap2Teo/TIL02_merged.bam
/home/sbyfield/HapMap2Teo/TIL03_merged.bam
/home/sbyfield/HapMap2Teo/TIL04-TIP454_merged.bam
/home/sbyfield/HapMap2Teo/TIL05_merged.bam
/home/sbyfield/HapMap2Teo/TIL06-TIP496_merged.bam
/home/sbyfield/HapMap2Teo/TIL07_merged.bam
/home/sbyfield/HapMap2Teo/TIL09_merged.bam
/home/sbyfield/HapMap2Teo/TIL10_merged.bam
/home/sbyfield/HapMap2Teo/TIL11_merged.bam
/home/sbyfield/HapMap2Teo/TIL12_merged.bam
/home/sbyfield/HapMap2Teo/TIL14-TIP498_merged.bam
/home/sbyfield/HapMap2Teo/TIL15_merged.bam
/home/sbyfield/HapMap2Teo/TIL16_merged.bam
/home/sbyfield/HapMap2Teo/TIL17_merged.bam
```

So I can run the following command to get the initial estimation of site allele frequency likelihood (SAF):

```{r,wrapper=TRUE, eval=FALSE}

angsd -bam /home/sbyfield/HapMap2Teo/teo.bam.file.list.txt -doSaf 1 -out teoFolded_chr10 -anc /home/sbyfield/HapMap2Teo/Zea_mays.AGPv3.22.dna.genome.fa -GL 2 -fold 1 -P 12 -r 10:1-10000000 

```
 
I extedned the region from 1:100,000 bp to 1:500,000 bp resulted in the follwoing error:
 
```{r,eval=FALSE}
        -> Reading fasta: /home/sbyfield/HapMap2Teo/Zea_mays.AGPv3.22.dna.genome.fa
        -> Parsing 15 number of samples
        -> Printing at chr: 10 pos:5698 chunknumber 100
        -> Printing at chr: 10 pos:7154 chunknumber 200
        -> Printing at chr: 10 pos:26725 chunknumber 300
        -> Printing at chr: 10 pos:29944 chunknumber 400
        -> Printing at chr: 10 pos:41538 chunknumber 500
        -> Printing at chr: 10 pos:44283 chunknumber 600
        -> Printing at chr: 10 pos:46373 chunknumber 700
        -> Printing at chr: 10 pos:51852 chunknumber 800
        -> Printing at chr: 10 pos:51952 chunknumber 900
PROBS at: 10    52032
        -> Printing at chr: 10 pos:70089 chunknumber 1000
        -> Printing at chr: 10 pos:70974 chunknumber 1100
        -> Printing at chr: 10 pos:123765 chunknumber 1200
PROBS at: 10    143508
        -> Printing at chr: 10 pos:143560 chunknumber 1300
        -> Printing at chr: 10 pos:144692 chunknumber 1400
PROBS at: 10    146774
        -> Printing at chr: 10 pos:147193 chunknumber 1500
        -> Printing at chr: 10 pos:176348 chunknumber 1600
        -> Printing at chr: 10 pos:176962 chunknumber 1700
        -> Printing at chr: 10 pos:182529 chunknumber 1800
        -> Printing at chr: 10 pos:207307 chunknumber 1900
        -> Printing at chr: 10 pos:266486 chunknumber 2000
        -> Printing at chr: 10 pos:292877 chunknumber 2100
        -> Printing at chr: 10 pos:317113 chunknumber 2200
        -> Printing at chr: 10 pos:372899 chunknumber 2300
        -> Printing at chr: 10 pos:443060 chunknumber 2400
        -> Printing at chr: 10 pos:475084 chunknumber 2500

        -> Done reading data waiting for calculations to finish
        -> Done waiting for threads
        -> Output filenames:
                ->"smallFolded_10_100000.arg"
                ->"smallFolded_10_100000.saf"
                ->"smallFolded_10_100000.saf.pos.gz"
        -> Tue Oct 28 15:07:25 2014
        -> Arguments and parameters for all analysis are located in .arg file
        [ALL done] cpu-time used =  43.92 sec
        [ALL done] walltime used =  25.00 sec

real    0m0.000s
user    0m0.000s
sys     0m0.000s
```

I examined extending the region to 1:1,000,000 bp with:

```{r,wrapper=TRUE, eval=FALSE}

angsd -bam /home/sbyfield/HapMap2Teo/teo.bam.file.list.txt -doSaf 1 -out teoFolded_chr10 -anc /home/sbyfield/HapMap2Teo/Zea_mays.AGPv3.22.dna.genome.fa -GL 2 -fold 1 -P 12 -r 10:1-1000000 -minMapQ 1 -minQ 20

```

and got this error in the stderr log file:

```{r,eval=FALSE}
        -> Reading fasta: /home/sbyfield/HapMap2Teo/Zea_mays.AGPv3.22.dna.genome.fa
        -> Parsing 15 number of samples
        -> Printing at chr: 10 pos:5698 chunknumber 100
        -> Printing at chr: 10 pos:7154 chunknumber 200
        -> Printing at chr: 10 pos:26725 chunknumber 300
        -> Printing at chr: 10 pos:29944 chunknumber 400
        -> Printing at chr: 10 pos:41538 chunknumber 500
        -> Printing at chr: 10 pos:44283 chunknumber 600
        -> Printing at chr: 10 pos:46373 chunknumber 700
        -> Printing at chr: 10 pos:51852 chunknumber 800
        -> Printing at chr: 10 pos:51952 chunknumber 900
PROBS at: 10    52032
        -> Printing at chr: 10 pos:70089 chunknumber 1000
        -> Printing at chr: 10 pos:70974 chunknumber 1100
        -> Printing at chr: 10 pos:123765 chunknumber 1200
PROBS at: 10    143508
        -> Printing at chr: 10 pos:143560 chunknumber 1300
        -> Printing at chr: 10 pos:144692 chunknumber 1400
PROBS at: 10    146774
        -> Printing at chr: 10 pos:147193 chunknumber 1500
        -> Printing at chr: 10 pos:176348 chunknumber 1600
        -> Printing at chr: 10 pos:176962 chunknumber 1700
        -> Printing at chr: 10 pos:182529 chunknumber 1800
        -> Printing at chr: 10 pos:207307 chunknumber 1900
        -> Printing at chr: 10 pos:266486 chunknumber 2000
        -> Printing at chr: 10 pos:292877 chunknumber 2100
        -> Printing at chr: 10 pos:317113 chunknumber 2200
        -> Printing at chr: 10 pos:372899 chunknumber 2300
        -> Printing at chr: 10 pos:443060 chunknumber 2400
        -> Printing at chr: 10 pos:475084 chunknumber 2500
        -> Printing at chr: 10 pos:537668 chunknumber 2600
        -> Printing at chr: 10 pos:549090 chunknumber 2700
        -> Printing at chr: 10 pos:574173 chunknumber 2800
        -> Printing at chr: 10 pos:589414 chunknumber 2900
        -> Printing at chr: 10 pos:615307 chunknumber 3000
        -> Printing at chr: 10 pos:633719 chunknumber 3100
        -> Printing at chr: 10 pos:651276 chunknumber 3200
        -> Printing at chr: 10 pos:667980 chunknumber 3300
        -> Printing at chr: 10 pos:687278 chunknumber 3400
        -> Printing at chr: 10 pos:703154 chunknumber 3500
        -> Printing at chr: 10 pos:730360 chunknumber 3600
        -> Printing at chr: 10 pos:750631 chunknumber 3700
        -> Printing at chr: 10 pos:770970 chunknumber 3800
        -> Printing at chr: 10 pos:789476 chunknumber 3900
        -> Printing at chr: 10 pos:808868 chunknumber 4000
        -> Printing at chr: 10 pos:829136 chunknumber 4100
        -> Printing at chr: 10 pos:861912 chunknumber 4200
        -> Printing at chr: 10 pos:888113 chunknumber 4300
        -> Printing at chr: 10 pos:911758 chunknumber 4400
        -> Printing at chr: 10 pos:935262 chunknumber 4500
        -> Printing at chr: 10 pos:958633 chunknumber 4600
        -> Printing at chr: 10 pos:974523 chunknumber 4700

        -> Done reading data waiting for calculations to finish
        -> Done waiting for threads
        -> Output filenames:
                ->"smallFolded_10_100000.arg"
                ->"smallFolded_10_100000.saf"
                ->"smallFolded_10_100000.saf.pos.gz"
        -> Tue Oct 28 15:16:32 2014
        -> Arguments and parameters for all analysis are located in .arg file
        [ALL done] cpu-time used =  82.42 sec
        [ALL done] walltime used =  38.00 sec

real    0m0.000s
user    0m0.000s
```
I extedned the region to 10,000,000 bp. Next it is probably wise to go ahead an see if I can move through the rest of the analyses and actually producce a folded SFS.

The next step is to convert the .saf file to a SFS using:
```
realSFS
```

There there is some confusion in the wiki for ANGSD about exactly how to do this, sometimes it says you need to declare $2n+1$ chromosomes, sometimes $2n$ chromosomes and sometimes $n$, where $n$ is the number of samples. I have found that using $n$ gets ANGSD to run. For example, if I have 15 samples (as I do in this example) I will declare 15 chromosomes as an argument to **realSFS**:

```
realSFS teoFolded_chr10.saf 15 -maxIter 100 -P 12 > teoFolded_chr10.sfs
```

Here is the resulting SFS for the first 10,000,000 bp of chromosome 10 for 15 teosinte lines:

```{r}
sfs<-c(-0.192947, -2.444628, -3.249441, -4.179364, -4.586453, -5.137299 ,-5.489250, -5.845022, -6.020604, -6.241799, -6.441396, -6.546019, -6.785617, -6.850590, -6.869085 ,-7.022943)
barplot(exp(sfs[-1]),col="darkgrey", names.arg=1:(length(sfs)-1), ylab="probability",xlab="minor allele freqquency", main = "Chr10:1:10,000,000")

```

This worked well, so I attempted the whole thing again for the entire Chr10 using:
```{wrapper=TRUE}
>angsd -bam /home/sbyfield/HapMap2Teo/teo.bam.file.list.txt -doSaf 1 -out teoFolded_chr10 -anc /home/sbyfield/HapMap2Teo/Zea_mays.AGPv3.22.dna.genome.fa -GL 2 -fold 1 -r 10 -P 12 -minMapQ 1 -minQ 20
>realSFS teoFolded_chr10.saf 15 -maxIter 100 -P 12 > teoFolded_chr10.sfs
```
```{r}
sfs<-c(-0.206044, -2.398034, -3.210098, -4.072419, -4.525486, -5.026914, -5.395742, -5.723438, -5.943467, -6.157773, -6.327133, -6.439034, -6.542996, -6.667280, -6.892473 -7.044611)
barplot(exp(sfs[-1]),col="darkgrey", names.arg=1:(length(sfs)-1), ylab="probability",xlab="minor allele freqquency", main = "Chr10")

```

This worked well also so I extended it to the whole genome using:
```
>angsd -bam /home/sbyfield/HapMap2Teo/teo.bam.file.list.txt -doSaf 1 -out teoFolded -anc /home/sbyfield/HapMap2Teo/Zea_mays.AGPv3.22.dna.genome.fa -GL 2 -fold 1 -P 18 -minMapQ 1 -minQ 20
>realSFS teoFolded.saf 15 -maxIter 100 -P 18 > teoFolded.sfs
```

###Step2: Calculate the thetas for each site

The next step is too calculate site wise estimates of theta for the region of interest. This can be acheived with a command like this:
```
>angsd -bam bam.filelist -out out -doThetas 1 -doSaf 1 -pest out.sfs -anc chimpHg19.fa -GL 2
```    

So for jsut the Chr10 data my command looks like:
```
>angsd -bam /home/sbyfield/HapMap2Teo/teo.bam.file.list.txt -out teoThetas_ch10 -doThetas 1 -doSaf 1 -fold 1 -pest teoFolded_chr10.sfs -anc Zea_mays.AGPv3.22.dna.genome.fa -GL 2 -P 12 -r 10:1-10000000 -minMapQ 1 -minQ 20
```

So to take a look at the data you can do:

```
gunzip -c teoThetas_ch10.thetas.gz | head
```

The ouput looks like this..

```
#Chromo  Pos	Watterson	Pairwise	thetaSingleton	thetaH	thetaL
10	19	-3.057582	-3.592928	-Inf	-Inf	-Inf
10	20	-3.057582	-3.592928	-Inf	-Inf	-Inf
10	21	-3.057582	-3.592928	-Inf	-Inf	-Inf
10	22	-3.057582	-3.592928	-Inf	-Inf	-Inf
10	23	-3.057582	-3.592928	-Inf	-Inf	-Inf
10	24	-3.057582	-3.592928	-Inf	-Inf	-Inf
10	25	-3.057582	-3.592928	-Inf	-Inf	-Inf
10	26	-3.057582	-3.592928	-Inf	-Inf	-Inf
10	27	-3.057582	-3.592928	-Inf	-Inf	-Inf
```

Note that the last three columns cannot be calculated with a folded spectrum. It's not important for calculating Tajima's D in this case. The next step is to create a BED file of the genome region.

```
#create a binary version of thete.thetas.gz 
misc/thetaStat make_bed teoThetas_ch10.thetas.gz
```

