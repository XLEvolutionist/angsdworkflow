---
title: "Estimating the Site Frequency Spectrum, Thetas and Tajima's D using ANGSD"
output: html_document
---
<br>
<br>


This is a document detailing how to process mapped NGS reads (sorted and indexed .bam files), and derive the SFS, site-wise estimates of Theta and Tajima's D using [ANGSD](http://popgen.dk/wiki/index.php/ANGSD). This is based on the wiki entry [here](http://popgen.dk/angsd/index.php/Tajima). At the moment this is estiamted based on several teosinte samples from the HapMap2 project. These are stored on Farm in 

* /group/jrigrp3/bottleneckProject/mergedBams

The examples TIL\*.bam are all teosinte, but TIL8 and TIL25 are *Z. mays mexicana* and will be removed from future analysis. The remiaing TIL\*.bam accessions are all *Zea mays parviglumis* and can be analysed together. 

In order to process the data the order of opporations should be roughly:

1.  Estiamte the SFS.
2.  Estimate Thetas
3.  Measure Statistics of deviation from neutrality.

Below is an example of work flow given in the [wiki](http://popgen.dk/angsd/index.php/Tajima), enabling the eventual estimation of Tajima's D.<br>

<br>

```{r,wrapper=TRUE, eval=FALSE}
    ./angsd -bam bam.filelist -doSaf 1 -anc chimpHg19.fa -GL 2 -P 24 -out out 
    ./misc/realSFS out.saf 20 -P 24 > out.sfs
    ./angsd -bam bam.filelist -out out -doThetas 1 -doSaf 1 -pest out.sfs -anc chimpHg19.fa -GL 2
    ./misc/thetaStat make_bed out.thetas.gz
    #Estimate for every Chromosome/scaffold
    ./misc/thetaStat do_stat out.thetas.gz -nChr 20
    #Do a sliding window analysis based on the output from the make_bed command.
    ./misc/thetaStat do_stat out.thetas.gz -nChr 20 -win 50000 -step 10000  -outnames theta.thetasWindow.gz
```

<br>

###Step1: Estimating the SFS in Teosinte (*Zea mays ssp. parviglumis*)

First estimate the site allele frequency likelihood. This requires several things listed below:

**1**.  A file with listed, one per line, all the .bam files you want to analyse. You can grab the files you need by cd'ing to the dir they are in and executing this code on the command line. 
<br>

```{r,wrapper=TRUE, eval=FALSE}
ls $PWD/*.bam > bam.list
```
<br>

**2**.  Choose which method you want to use with: 

```{r,wrapper=TRUE, eval=FALSE}
-doSaf [int 1-4]
```

There are four options listed in detail [here](http://popgen.dk/angsd/index.php/SFS_Estimation).

<br>

**3**. Define your ancestral allele using the flag:
```{r,wrapper=TRUE, eval=FALSE}
-anc <path/to/referencegenome>
```

In my case we do not know the ancestral allele state, which means instead of derived allele SFS we need a minor allele SFS (a folded SFS). We can still provide an ancestral estimate using the reference genome (B73), but once folding is complete in becomes a minor allele SFS. We need to specify that we want a folded SFS wiht:
```{r,wrapper=TRUE, eval=FALSE}
-fold 1
```
<br>

**4**.  Define the method for estimating Genotype Likelihoods:
```{r,wrapper=TRUE, eval=FALSE}
-GL [int 1-4]
```

details of the different methods are provided [here](http://popgen.dk/angsd/index.php/Genotype_likelihoods).

<br>


**5**. Define the number of processors to use with:
```{r,wrapper=TRUE, eval=FALSE}
-P [int]
```
 
 <br>
 
**6**. Define the outfile name using:
```{r,wrapper=TRUE, eval=FALSE}
-out <path/to/outfile>
```
there are several output files and a suffix will be added to each file.

<br>

You can also define the region of the genome you would like to analyse. On the first pass we will limit our analysis of the genome to the first 500,000 bp of chromosome 10 using:


```{r,wrapper=TRUE, eval=FALSE}
-r 10:1-100000
```

I have a bam.list file that has the following accessions listed:

```{r,wrapper=TRUE, eval=FALSE}
/home/sbyfield/HapMap2Teo/TIL01_merged.bam
/home/sbyfield/HapMap2Teo/TIL02_merged.bam
/home/sbyfield/HapMap2Teo/TIL03_merged.bam
/home/sbyfield/HapMap2Teo/TIL04-TIP454_merged.bam
/home/sbyfield/HapMap2Teo/TIL05_merged.bam
/home/sbyfield/HapMap2Teo/TIL06-TIP496_merged.bam
/home/sbyfield/HapMap2Teo/TIL07_merged.bam
/home/sbyfield/HapMap2Teo/TIL09_merged.bam
/home/sbyfield/HapMap2Teo/TIL10_merged.bam
/home/sbyfield/HapMap2Teo/TIL11_merged.bam
/home/sbyfield/HapMap2Teo/TIL12_merged.bam
/home/sbyfield/HapMap2Teo/TIL14-TIP498_merged.bam
/home/sbyfield/HapMap2Teo/TIL15_merged.bam
/home/sbyfield/HapMap2Teo/TIL16_merged.bam
/home/sbyfield/HapMap2Teo/TIL17_merged.bam
```

So I can run the following command to get the initial estimation of site allele frequency likelihood (SAF):

```{r,wrapper=TRUE, eval=FALSE}

angsd -bam /home/sbyfield/HapMap2Teo/teo.bam.file.list.txt -doSaf 1 -out smallFolded_10_100000 -anc /home/sbyfield/HapMap2Teo/Zea_mays.AGPv3.22.dna.genome.fa -GL 2 -fold 1 -P 12 -r 10:1-500000 -minMapQ 1 -minQ 20

```
 I have added in some quiltiy control flags.
 
Also extedned the region from 1:100,000 bp to 1:500,000 bp resulted in the follwoing error:
 
```{r,eval=FALSE}
        -> Reading fasta: /home/sbyfield/HapMap2Teo/Zea_mays.AGPv3.22.dna.genome.fa
        -> Parsing 15 number of samples
        -> Printing at chr: 10 pos:5698 chunknumber 100
        -> Printing at chr: 10 pos:7154 chunknumber 200
        -> Printing at chr: 10 pos:26725 chunknumber 300
        -> Printing at chr: 10 pos:29944 chunknumber 400
        -> Printing at chr: 10 pos:41538 chunknumber 500
        -> Printing at chr: 10 pos:44283 chunknumber 600
        -> Printing at chr: 10 pos:46373 chunknumber 700
        -> Printing at chr: 10 pos:51852 chunknumber 800
        -> Printing at chr: 10 pos:51952 chunknumber 900
PROBS at: 10    52032
        -> Printing at chr: 10 pos:70089 chunknumber 1000
        -> Printing at chr: 10 pos:70974 chunknumber 1100
        -> Printing at chr: 10 pos:123765 chunknumber 1200
PROBS at: 10    143508
        -> Printing at chr: 10 pos:143560 chunknumber 1300
        -> Printing at chr: 10 pos:144692 chunknumber 1400
PROBS at: 10    146774
        -> Printing at chr: 10 pos:147193 chunknumber 1500
        -> Printing at chr: 10 pos:176348 chunknumber 1600
        -> Printing at chr: 10 pos:176962 chunknumber 1700
        -> Printing at chr: 10 pos:182529 chunknumber 1800
        -> Printing at chr: 10 pos:207307 chunknumber 1900
        -> Printing at chr: 10 pos:266486 chunknumber 2000
        -> Printing at chr: 10 pos:292877 chunknumber 2100
        -> Printing at chr: 10 pos:317113 chunknumber 2200
        -> Printing at chr: 10 pos:372899 chunknumber 2300
        -> Printing at chr: 10 pos:443060 chunknumber 2400
        -> Printing at chr: 10 pos:475084 chunknumber 2500

        -> Done reading data waiting for calculations to finish
        -> Done waiting for threads
        -> Output filenames:
                ->"smallFolded_10_100000.arg"
                ->"smallFolded_10_100000.saf"
                ->"smallFolded_10_100000.saf.pos.gz"
        -> Tue Oct 28 15:07:25 2014
        -> Arguments and parameters for all analysis are located in .arg file
        [ALL done] cpu-time used =  43.92 sec
        [ALL done] walltime used =  25.00 sec

real    0m0.000s
user    0m0.000s
sys     0m0.000s
```

I examined extending the region to 1:1,000,000 bp with:

```{r,wrapper=TRUE, eval=FALSE}

angsd -bam /home/sbyfield/HapMap2Teo/teo.bam.file.list.txt -doSaf 1 -out smallFolded_10_100000 -anc /home/sbyfield/HapMap2Teo/Zea_mays.AGPv3.22.dna.genome.fa -GL 2 -fold 1 -P 12 -r 10:1-1000000 -minMapQ 1 -minQ 20

```

and got this error in the stderr log file:

```{r,eval=FALSE}
        -> Reading fasta: /home/sbyfield/HapMap2Teo/Zea_mays.AGPv3.22.dna.genome.fa
        -> Parsing 15 number of samples
        -> Printing at chr: 10 pos:5698 chunknumber 100
        -> Printing at chr: 10 pos:7154 chunknumber 200
        -> Printing at chr: 10 pos:26725 chunknumber 300
        -> Printing at chr: 10 pos:29944 chunknumber 400
        -> Printing at chr: 10 pos:41538 chunknumber 500
        -> Printing at chr: 10 pos:44283 chunknumber 600
        -> Printing at chr: 10 pos:46373 chunknumber 700
        -> Printing at chr: 10 pos:51852 chunknumber 800
        -> Printing at chr: 10 pos:51952 chunknumber 900
PROBS at: 10    52032
        -> Printing at chr: 10 pos:70089 chunknumber 1000
        -> Printing at chr: 10 pos:70974 chunknumber 1100
        -> Printing at chr: 10 pos:123765 chunknumber 1200
PROBS at: 10    143508
        -> Printing at chr: 10 pos:143560 chunknumber 1300
        -> Printing at chr: 10 pos:144692 chunknumber 1400
PROBS at: 10    146774
        -> Printing at chr: 10 pos:147193 chunknumber 1500
        -> Printing at chr: 10 pos:176348 chunknumber 1600
        -> Printing at chr: 10 pos:176962 chunknumber 1700
        -> Printing at chr: 10 pos:182529 chunknumber 1800
        -> Printing at chr: 10 pos:207307 chunknumber 1900
        -> Printing at chr: 10 pos:266486 chunknumber 2000
        -> Printing at chr: 10 pos:292877 chunknumber 2100
        -> Printing at chr: 10 pos:317113 chunknumber 2200
        -> Printing at chr: 10 pos:372899 chunknumber 2300
        -> Printing at chr: 10 pos:443060 chunknumber 2400
        -> Printing at chr: 10 pos:475084 chunknumber 2500
        -> Printing at chr: 10 pos:537668 chunknumber 2600
        -> Printing at chr: 10 pos:549090 chunknumber 2700
        -> Printing at chr: 10 pos:574173 chunknumber 2800
        -> Printing at chr: 10 pos:589414 chunknumber 2900
        -> Printing at chr: 10 pos:615307 chunknumber 3000
        -> Printing at chr: 10 pos:633719 chunknumber 3100
        -> Printing at chr: 10 pos:651276 chunknumber 3200
        -> Printing at chr: 10 pos:667980 chunknumber 3300
        -> Printing at chr: 10 pos:687278 chunknumber 3400
        -> Printing at chr: 10 pos:703154 chunknumber 3500
        -> Printing at chr: 10 pos:730360 chunknumber 3600
        -> Printing at chr: 10 pos:750631 chunknumber 3700
        -> Printing at chr: 10 pos:770970 chunknumber 3800
        -> Printing at chr: 10 pos:789476 chunknumber 3900
        -> Printing at chr: 10 pos:808868 chunknumber 4000
        -> Printing at chr: 10 pos:829136 chunknumber 4100
        -> Printing at chr: 10 pos:861912 chunknumber 4200
        -> Printing at chr: 10 pos:888113 chunknumber 4300
        -> Printing at chr: 10 pos:911758 chunknumber 4400
        -> Printing at chr: 10 pos:935262 chunknumber 4500
        -> Printing at chr: 10 pos:958633 chunknumber 4600
        -> Printing at chr: 10 pos:974523 chunknumber 4700

        -> Done reading data waiting for calculations to finish
        -> Done waiting for threads
        -> Output filenames:
                ->"smallFolded_10_100000.arg"
                ->"smallFolded_10_100000.saf"
                ->"smallFolded_10_100000.saf.pos.gz"
        -> Tue Oct 28 15:16:32 2014
        -> Arguments and parameters for all analysis are located in .arg file
        [ALL done] cpu-time used =  82.42 sec
        [ALL done] walltime used =  38.00 sec

real    0m0.000s
user    0m0.000s
```
